<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>Elasticsearch best practice</title>

    <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
    <meta name="author" content="Hakim El Hattab">

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/black.css" id="theme">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <style>
        .background-image-overlay {
            background: black !important;
            padding: 10px;
            opacity: 0.8;
        }
    </style>

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>

    <div class="reveal">

        <div class="slides">
            <section data-background="images/relevance-scoring.jpg">
                <h1>Elasticsearch best practice</h1>
                <p>
                    <small>Serhii Shepel</small>
                </p>
                <aside class="notes">
                    <ul>
                        <li>
                            Velkommen, i dag skal jeg holde en veldig kort introduksjon til Elasticsearch.
                        </li>
                    </ul>
                </aside>
            </section>

            <section data-title="Agenda">
                <h2>Agenda</h2>
                <ul>
                    <li class="fragment">Elasticsearch
                        <ul>
                            <li>What is</li>
                            <li>How to get started</li>
                        </ul>
                    </li>
                    <li class="fragment">Basic Concepts</li>
                    <li class="fragment">How does a search engine work</li>
                    <li class="fragment">Mapping</li>
                    <li class="fragment">Search</li>
                    <li class="fragment">Own experience</li>
                </ul>
            </section>

            <section data-title="Elasticsearch" data-background="white">
                <img style="box-shadow: none;" data-src="images/introduction.svg">
                <aside class="notes">
                    <ul>
                        <li>Jeg skal nå bruke sirka 1 minutt på å si hva Elasticsearch er.
                            <ul>
                                <li>
                                    Lucene
                                    <ul>
                                        <li>Cumbersome to use directly</li>
                                        <li>Provides few features for scaling past a single machine</li>
                                    </ul>
                                </li>
                                <li>
                                    Real time
                                    <ul>
                                        <li>Det går fort å indeksere dokumenter</li>
                                        <li>Data er tilgjenglig for søk nesten med en gang etter indeksering</li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                    </ul>
                </aside>
            </section>

            <section data-title="How to get started with Elasticsearch?">
                <section>
                    <h2>How to get started with Elasticsearch?</h2>
                    <aside class="notes">
                        <ul>
                            <li>Så hvordan kan man komme igang med Elasticsearch...</li>
                        </ul>
                    </aside>
                </section>

                <section>
                    <h2>It is that easy</h2>
                    <ul>
                        <li>Download Elasticsearch from www.elastic.co</li>
                        <li>Elasticsearch only requires Java to run</li>
                    </ul>
                    <pre><code class="hljs" data-trim contenteditable>
    wget https://download.elasticsearch.org/elasticsearch/release/...
    tar -zxvf elasticsearch-2.2.0.tar.gz
    cd elasticsearch-2.2.0/bin
    ./elasticsearch.sh
                    </code></pre>
                </section>

                <section>
                    <h2>Zero configurations</h2>
                    <ul>
                        <li>Elasticsearch just works
                            <ul>
                                <li>No configuration is needed</li>
                                <li>It has sensible defaults settings</li>
                            </ul>
                        </li>
                    </ul>
                    <aside class="notes">
                        It is easy to get started with Elasticsearch!
                    </aside>
                </section>

                <section>
                    <h2>Is Elasticsearch alive?</h2>

                    <p>You can access it at http://localhost:9200 on your web browser, which returns this:</p>
                    <pre class="fragment"><code class="hljs" data-trim contenteditable>
{
    "status":200,
    "name":"Cypher",
    "cluster_name":"elasticsearch",
    "version":{
        "number":"1.5.2",
        "build_hash":"62ff9868b4c8a0c45860bebb259e21980778ab1c",
        "build_timestamp":"2015-04-27T09:21:06Z",
        "build_snapshot":false,
        "lucene_version":"4.10.4"
    },
    "tagline":"You Know, for Search"
}                    
                    </code></pre>
                </section>

                <section>
                    <h2>REST API</h2>

                    <ul>
                        <li>Elasticsearch hides the complexities of Lucene behind a REST API
                            <ul>
                                <li>POST (create)</li>
                                <li>GET (read)</li>
                                <li>PUT (update)</li>
                                <li>DELETE (delete)</li>
                            </ul>
                    </ul>
                </section>

                <section>
                    <h2>DEMO - CURL works just fine</h2>
                    <img height="300" data-src="images/crud.png" />
                    <ul>
                        <li class="fragment">An index is like a database</li>
                        <li class="fragment">An type is like a SQL table</li>
                    </ul>
                </section>

                <section>
                    <h2>What is stored in Elasticsearch?</h2>

                    <p>JSON documents!</p>
                    <pre class="json"><code class="hljs" data-trim contenteditable>
{
    "title": "Introduction to Elasticsearch",
    "date": "2016-04-07",
    "author": "Serhii Shepel"
}
                    </code></pre>
                </section>

                <section>
                    <h2>Get</h2>
                    <pre><code class="hljs" data-trim contenteditable>
                        $curl -X GET localhost:9200/big-one/pizza/1
                    </code></pre>
                    <p>Result:</p>
                    <pre class="fragment"><code class="hljs" data-trim contenteditable>
{
    "_index":"big-one",
    "_type":"pizza",
    "_id":"1",
    "_version":1,
    "found":true,
    "_source":{
        "name":"California Sunset Chicken"
    }
}
                    </code></pre>
                </section>

                <section>
                    <h2>Update</h2>
                    <pre><code class="hljs" data-trim contenteditable>
$curl -X PUT localhost:9200/big-one/pizza/1 --data
'{
    "name":"California Sunset Chicken Awesome"
}'
                    </code></pre>
                    <p>Result:</p>
                    <pre class="fragment"><code class="hljs" data-trim contenteditable>
{
    "_index":"big-one",
    "_type":"pizza",
    "_id":"1",
    "_version":2,
    "created":false
}
                   </code></pre>
                </section>


                <section>
                    <h2>Delete</h2>
                    <pre><code class="hljs" data-trim contenteditable>
                        $curl -X DELETE localhost:9200/big-one/pizza/1
                    </code></pre>
                </section>

                <!--<section>
                    <h2>So far, all we have is a NoSQL document store which is fast, reliable, scalable and easy to use! Now
                        to the really cool part, full-text search...</h2>
                </section>-->

                <section>
                    <h2>So far</h2>
                    <ul>
                        <li>All we have is NoSQL document store which is
                            <ul>
                                <li>Fast</li>
                                <li>Scalable</li>
                                <li>Easy to use</li>
                            </ul>
                        </li>
                    </ul>
                </section>
            </section>

            <section data-title="Basic Concepts">
                <section>
                    <h2>Basic Concepts</h2>
                    <ul>
                        <li>Index:
                            <ul>
                                <li>An index is like a ‘database’ in a relational database. It has a
                                    mapping which defines multiple types. </li>
                                <li>An index is a logical namespace which maps to one or more primary
                                    shards and can have zero or more replica shards</li>
                            </ul>
                        </li>
                        <li>Type:
                            <ul>
                                <li>A type is like a ‘table’ in a relational database. Each type has a
                                    list of fields that can be specified for documents of that type. The mapping defines
                                    how each field in the document is analyzed</li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    <h2>Basic Concepts</h2>
                    <ul>
                        <li>Document:
                            <ul>
                                <li>A document is a JSON document which is stored in elasticsearch. It
                                    is like a row in a table in a relational database. Each document is stored in an
                                    index and has a type and an id.
                                </li>
                                <li>A document is a JSON object (also known in other languages as a
                                    hash / hashmap/ associative array) which contains zero or more fields, or key-value
                                    pairs. The original JSON document that is indexed will be stored in the _source
                                    field, which is returned by default when getting or searching for a document.
                                </li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    <h2>Basic Concepts</h2>
                    <ul>
                        <li>Field:
                            <ul>
                                <li>A document contains a list of fields, or key-value pairs. The value
                                    can be a simple (scalar) value (ega string, integer, date), or a nested structure
                                    like an array or an object. A field is similar to a column in a table in a
                                    relational database.

                                </li>
                                <li>The mapping for each field has a field ‘type’ (not to be confused
                                    with document type) which indicates the type of data that can be stored in that
                                    field, eginteger, string, object. The mapping also allows you to define (amongst
                                    other things) how the value for a field should be analyzed.
                                </li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    <h2>Basic Concepts</h2>
                    <ul>
                        <li>Mapping:
                            <ul>
                                <li>A mapping is like a ‘schema definition’ in a relational database.
                                    Each index has a mapping, which defines each type within the index, plus a number of
                                    index-wide settings. A mapping can either be defined explicitly, or it will be
                                    generated automatically when a document is indexed
                                </li>
                            </ul>
                        </li>
                    </ul>
                </section>
            </section>

            <section data-title="How does a search engine work?">
                <section>
                    <h2>How does a search engine work?</h2>
                    <aside class="notes">
                        <ul>
                            <li>
                                Hvordan fungerer en søkemotor?
                            </li>
                        </ul>
                    </aside>
                </section>

                <section data-background="images/overflow2.jpg">
                    <blockquote class="background-image-overlay">
                        Your document collection is big! <br />
                        Scan through all the documents every time you search for something?
                    </blockquote>
                    <aside class="notes">
                        <ul>
                            <li>
                                Dette ville tatt evigheter
                            </li>
                        </ul>
                    </aside>
                </section>

                <section data-background="images/kokeboka4.png">
                    <blockquote class="background-image-overlay">
                        Pre-process the documents and create an index!
                    </blockquote>
                    <!--<aside class="notes">
                    To make your queries fast and efficient a search engine will pre-process the documents and create an
                    index
                </aside>-->
                    <aside class="notes">
                        <ul>
                            <li>
                                For å gjøre dine søk raskt og effektivt vil en søkemotor forhåndsbehandle dokumentene og
                                lage en index
                            </li>
                        </ul>
                    </aside>
                </section>

                <section data-background="white">
                    <h2>Create an inverted index</h2>
                    <img style="box-shadow: none;" data-src="images/inverted-index-1.svg">
                    <!--<aside class="notes">
                    The inverted index maps terms to documents containing the term.
                </aside>-->
                    <aside class="notes">
                        <ul>
                            <li>Man lager seg da noe som heter en "invertert index"</li>
                            <li>På venstre siden har vi tre dokumenter...</li>
                            <li>Siden dette er en BigOne konferanse, så vil mye av innholdet i dag være pizza
                                relatert...</li>
                            <li>Det som skjer er at man lager seg en invertert index av disse dokumentene (dokumentene
                                blir
                                indeksert, som det heter)
                            </li>
                            <li>En invertert index (som vi ser på høyre side her nå) inneholder alle ordene som finnes i
                                dokumentene, og for hvert ord så
                                lister man opp hvilke dokumenter som inneholder ordet...
                            </li>
                            <li>Så ordet "pizza" finnes i dokument 0 og 2</li>
                        </ul>
                    </aside>
                </section>

                <section data-background="white">
                    <h2>Find unique terms</h2>
                    <img style="box-shadow: none;" data-src="images/inverted-index-2.svg">
                    <aside class="notes">
                        <ul>
                            <li>
                                Så hvordan finner man unike ord?
                                <ul>
                                    <li>
                                        Hvis man f.eks tar for seg dokumentet "Turles loves pizza", så vil det gå
                                        igjennom forskjellige steg...
                                        <ul>
                                            <li>Man splitter opp dokumentet i ord</li>
                                            <li>Man gjør alle bokstaver små</li>
                                            <li>Man finner grunnstammer for ord, f.eks "Loves" blir "love"</li>
                                        </ul>
                                    </li>
                                    <li>
                                        Dette er ett forenklet eksempel...
                                    </li>
                                </ul>
                            </li>
                        </ul>
                    </aside>
                </section>

                <section data-background="white">
                    <h2>Search against the inverted index</h2>
                    <img style="box-shadow: none;" data-src="images/inverted-index-3.svg">
                </section>
            </section>

            <section data-title="Mapping">
                <section>
                    <h2>Mapping</h2>
                    <ul>
                        <li>Each field has a data type which can be:
                            <ul>
                                <li>a simple type like <i>text</i>, <i>keyword</i>, <i>date</i>,
                                    <i>long</i>, <i>double</i>, <i>boolean</i> or <i>ip</i> .</li>
                                <li>a type which supports the hierarchical nature of JSON such as
                                    <i>object</i> or <i>nested</i>.</li>
                                <li>or a specialised type like <i>geo_point</i>, <i>geo_shape</i>, or
                                    <i>completion</i>>.</li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    <h2>Mapping</h2>
                    <ul>
                        <li>It is often useful to index the same field in different ways for different
                            purposes. For instance, a <i>string</i> field could be indexed as a <i>text</i> field for
                            full-text search, and as a <i>keyword</i> field for sorting or aggregations. Alternatively,
                            you could
                            index a string field with the <i>standard</i> analyzer, the english analyzer, and the french
                            analyzer.
                        </li>
                        <li>This is the purpose of multi-fields. Most datatypes support multi-fields
                            via the fields parameter.
                        </li>
                    </ul>
                </section>
                <section>
                    <pre><code class="csharp" style="max-height: 650px">    
public class CustomerInfoSearchDocumentMap 
    : PropertiesDescriptor&lt;CustomerInfoSearchDocument&gt;
{
    public CustomerInfoSearchDocumentMap()
    {
        Keyword(p => p.Name(n => n.Id).Index());
        Number(p => p.Name(n => n.Age).Index());
        Text(p => p.Name(n => n.FirstName)
                .Analyzer(Analyzer.PrimaryField)
                .SearchAnalyzer(Analyzer.PrimaryFieldSearch)
        );
        Text(p => p.Name(n => n.LastName)
                .Analyzer(Analyzer.PrimaryField)
                .SearchAnalyzer(Analyzer.PrimaryFieldSearch)
        );
        Text(p => p.Name(n => n.FullName).Index()
                .Fields(fs => fs
                    .Keyword(k => k
                        .Name(n => n.FullName.Suffix(Normalizer.Sort))
                        .Normalizer(Normalizer.Sort))
                    );
        }
}
                                </code></pre>
                </section>

                <section>
                    <h2>Analyzer</h2>
                    <ul>
                        <li>Tokenizer</li>
                        <li>Filters</li>
                        <li>CharFilters</li>
                    </ul>
                </section>
                <section>
                    <h2>Tokenizer</h2>
                    <ul>
                        <li>Standard Tokenizer:
                            <ul>
                                <li>The standard tokenizer divides text into terms on word boundaries, as defined by the
                                    Unicode Text Segmentation algorithm. It removes most punctuation symbols. It is the
                                    best choice for most languages.
                                </li>
                            </ul>
                        </li>
                        <li>Letter Tokenizer
                            <ul>
                                <li>The letter tokenizer divides text into terms whenever it encounters a character
                                    which is not a letter.
                                </li>
                            </ul>
                        </li>
                        <li>Lowercase Tokenizer
                            <ul>
                                <li>The lowercase tokenizer, like the letter tokenizer, divides text into terms whenever
                                    it encounters a character which is not a letter, but it also lowercases all terms.
                                </li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    <h2>Tokenizer</h2>
                    <ul>
                        <li>Whitespace Tokenizer
                            <ul>
                                <li>The whitespace tokenizer divides text into terms whenever it encounters any
                                    whitespace character.
                                </li>
                            </ul>
                        </li>
                        <li>UAX URL Email Tokenizer
                            <ul>
                                <li>The uax_url_email tokenizer is like the standard tokenizer except that it recognises
                                    URLs and email addresses as single tokens.
                                </li>
                            </ul>
                        </li>
                        <li>Classic Tokenizer
                            <ul>
                                <li>The classic tokenizer is a grammar based tokenizer for the English Language.
                                </li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    <h2>Tokenizer</h2>
                    <ul>
                        <li>N-Gram Tokenizer</li>
                        <li>Edge N-Gram Tokenizer</li>
                    </ul>
                </section>
                <section>
                    <h2>Standart Tokenizer</h2>
                    <p>Example</p>
                    <pre><code class="hljs" data-trim contenteditable>
POST _analyze
{
    "tokenizer": "standard",
    "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}
                        </code></pre>
                    <div class="fragment">
                        <p>The above sentence would produce the following terms:</p>
                        <pre><code class="hljs" data-trim contenteditable>
[ The, 2, QUICK, Brown, Foxes, jumped, over, the, lazy, dog's, bone ]
                        </code></pre>
                    </div>
                </section>

                <section>
                    <h2>Ngram tokenizer</h2>
                    <p>Example</p>
                    <pre><code class="hljs" data-trim contenteditable>
POST _analyze
{
    "tokenizer": "ngram",
    "text": "Quick Fox"
}
                                </code></pre>
                    <div class="fragment">
                        <p>The above sentence would produce the following terms:</p>
                        <pre><code class="hljs" data-trim contenteditable>
[ Q, Qu, u, ui, i, ic, c, ck, k, F, Fo, o, ox, x ]
                                </code></pre>
                    </div>
                </section>
                <section>
                    <h2>Ngram tokenizer</h2>
                    <p>Configuration</p>
                    <ul>
                        <li>min_gram: Minimum length of characters in a gram. Defaults to 1.</li>
                        <li>max_gram: Maximum length of characters in a gram. Defaults to 2.</li>
                    </ul>
                </section>
                <section>
                    <h2>Ngram tokenizer</h2>
                    <p>Configuration</p>
                    <ul>
                        <li>token_chars: Character classes that should be included in a token. Elasticsearch will split
                            on characters that don’t belong to the classes specified. Defaults to [] (keep all
                            characters). Character classes may be any of the following:
                            <ul>
                                <li>letter — for example a, b</li>
                                <li>digit —  for example 3 or 7</li>
                                <li>whitespace —  for example " "</li>
                                <li>punctuation — for example ! or "</li>
                                <li>symbol —  for example $ or √</li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    <h2>Ngram tokenizer</h2>
                    <p>Example</p>
                    <pre><code class="hljs" data-trim contenteditable>
"min_gram": 2,
"max_gram": 3,
"token_chars": [
    "letter",
    "digit"
]

POST _analyze
{
    "tokenizer": "ngram",
    "text": "123 2 Quick"
}
                                    </code></pre>
                    <div class="fragment">
                        <p>The above sentence would produce the following terms:</p>
                        <pre><code class="hljs" data-trim contenteditable>
[12, 123, 23, Qu, Qui, ui, uic, ic, ick, ck]
                                    </code></pre>
                    </div>
                </section>
                <section>
                    <h2>Edge NGram Token Filter</h2>
                    <p>Example</p>
                    <pre><code class="hljs" data-trim contenteditable>
"min_gram": 2,
"max_gram": 10,
"token_chars": [
    "letter",
    "digit"
]

POST my_index/_analyze
{
    "analyzer": "my_analyzer",
    "text": "2 Quick Foxes."
}
                                            </code></pre>
                    <div class="fragment">
                        <p>The above sentence would produce the following terms:</p>
                        <pre><code class="hljs" data-trim contenteditable>
[ Qu, Qui, Quic, Quick, Fo, Fox, Foxe, Foxes ]
                                            </code></pre>
                    </div>
                </section>
                <section>
                    <h2>Filters</h2>
                    <ul>
                        <li>Lowercase</li>
                        <li>Ngram</li>
                        <li>EdgeNgram</li>
                        <li>ASCII Folding</li>
                        <li>Stop</li>
                        <li>Stemmer</li>
                    </ul>
                </section>
                <section>
                    <h2>ASCII Folding Filter</h2>
                    <p>Example of scandinavian_folding</p>
                    <pre><code class="hljs" data-trim contenteditable>
åÅäæÄÆ->a 
öÖøØ->o
                                                </code></pre>
                </section>
                <section>
                    <h2>Stop Token Filter</h2>
                    <p>Example</p>
                    <pre><code class="hljs" data-trim contenteditable>
"my_stop": {
    "type":       "stop",
    "stopwords": "_english_"
}

POST my_index/_analyze
{
    "analyzer": "my_analyzer",
    "text": "london is the capital of great britain"
}
                                            </code></pre>
                    <div class="fragment">
                        <p>The above sentence would produce the following terms:</p>
                        <pre><code class="hljs" data-trim contenteditable>
[ "london capital great britain" ]
                                            </code></pre>
                    </div>
                </section>
                <section>
                    <h2>Stemmer Token Filter</h2>
                    <p>Example</p>
                    <pre><code data-trim contenteditable>
Tryolabs -> tryolab
running	-> run
monkeys	-> monkei
KANGAROOS -> kangaroo
and	-> and
jumping	-> jump
elephants -> eleph
                                                    </code></pre>
                </section>
                <section>
                    <h2>Character Filters</h2>
                    <ul>
                        <li>HTML Strip Character Filter: The html_strip character filter strips out HTML elements like
                            <b> and decodes HTML entities like &amp;.</b>></li>
                        <li>Mapping Character Filter: The mapping character filter replaces any occurrences of the
                            specified strings with the specified replacements.</li>
                        <li>Pattern Replace Character Filter: The pattern_replace character filter replaces any
                            characters matching a regular expression with the specified replacement.</li>
                    </ul>
                </section>
                <section>
                    <h2>Fields</h2>
                    <pre><code data-trim contenteditable>
PUT my_index
{
    "mappings": {
    "properties": {
        "city": {
        "type": "text",
        "fields": {
            "raw": { 
            "type":  "keyword"
            }
        }
        }
    }
    }
}
    </code></pre>
                </section>

                <section>
                    <h2>Fields</h2>
                    <pre><code data-trim contenteditable>
GET my_index/_search
{
    "query": {
    "match": {
        "city": "york" 
    }
    },
    "sort": {
    "city.raw": "asc" 
    }
    }
}
        </code></pre>
                </section>
                <section>
                    <h2>Fields</h2>
                    <pre><code class="csharp" data-trim contenteditable>
Text(p => p.Name(n => n.FullName)
    .Fields(fs => fs
    .Keyword(k => k
        .Name(n => n.FullName.Suffix(Normalizer.Sort))
        .Normalizer(Normalizer.Sort))
    );
        </code></pre>
                </section>
                <section>
                    <h2>Nested vs Object</h2>
                    <pre><code class="csharp" data-trim contenteditable>
public class Book
{
    public int Id { get; set; }

    public string Title { get; set; }

    public IEnumerable<Author> Authors { get; set; }
}

public class Author
{
    public string First { get; set; }

    public string Last { get; set; }
}
            </code></pre>
                </section>
                <section>
                    <h2>Nested vs Object</h2>
                    <pre><code class="csharp" data-trim contenteditable>
public class BookMap 
    : PropertiesDescriptor&lt;Book&gt;
{
    public BookMap()
    {
        Keyword(p => p.Name(n => n.Id).Index());
        Text(p => p.Name(n => n.Title)
                .Analyzer(Analyzer.PrimaryField)
                .SearchAnalyzer(Analyzer.PrimaryFieldSearch)
        );
        
        Object&lt;Author&gt;(p => p.Name(n => n.Authors));
        Nested&lt;Author&gt;(p => p.Name(n => n.Authors));
}
                </code></pre>
                </section>
                <section>
                    
                    <pre><code data-trim contenteditable>
PUT book/_doc/1
{
    "title" : "Clean Code",
    "authors" : [ 
    {
        "first" : "Robert",
        "last" :  "Martin"
    },
    {
        "first" : "Kent",
        "last" :  "Beck"
    }]
}
                    </code></pre>
                    <div class="fragment">
                        <p>Would be transformed internally into a document that looks more like this in Object type
                            case:</p>
                        <pre><code data-trim contenteditable>
{
    "title" :        "clean code",
    "authors.first" : [ "robert", "kent" ],
    "authors.last" :  [ "martin", "beck" ]
}
                                                        </code></pre>
                    </div>

                </section>
                <section>
                        <h2>Nested vs Object</h2>
                        <pre><code data-trim contenteditable>
GET my_index/_search
{
    "query": {
    "bool": {
        "must": [
        { "match": { "authors.first": "robert" }},
        { "match": { "authors.last":  "beck" }}
        ]
    }
    }
}
                        </code></pre>
                    </section>
            </section>

            <section data-title="Search">
                <section>
                    <h2>Simple structure of Search</h2>
                    <pre><code class="hljs" style="max-height: 650px" data-trim contenteditable>
GET /shirts/_search
{
    "from": 0, 
    "size": 10,
    "query": {
        "bool": {
            "filter": [
            { "term": { "color": "red"   }}]
        }
    },
    "highlight" : {
        "fields" : {
            "content" : {}
        }
    },
    "aggs": {
        "models": {
            "terms": { "field": "model" } 
        }
    },
    "post_filter": { 
        "term": { "color": "red" }
    },
    "sort": ["_score","model"]
}
                                            </code></pre>
                </section>
                <section>
                    <h2>Aggregations</h2>
                    <a href="https://github.com/search?q=webgl" target="_blank">
                        <img height="600" width="800" data-src="images/aggregations.png" />
                    </a>
                </section>
                <section>
                    <pre><code class="hljs" style="max-height: 650px" data-trim contenteditable>
PUT /gitHubItem
{
    "mappings": {
        "_doc": {
            "properties": {
                "title": { "type": "text", "analyer": "my_analyzer" },
                "language": { "type": "keyword"}, //C#, Java, JavaScript
                "type": { "type": "keyword"} //Repository, Code, Issues
            }
        }
    }
}
                        </code></pre>
                </section>
                <section>
                    <pre><code class="hljs" style="max-height: 650px" data-trim contenteditable>
GET /gitHubItem/_search
{
    "query": {
        "bool": {
            "must" : [
            { "term" : { "language" : "C#" } },
            { "match" : { "title" : "webgl" } }]}
    },
    "aggs": {
        "all_items": { 
            global: {},
            "filter" : { "match" : { "title" : "webgl" } },
            "aggs": { "terms": { "field": "language" } }
         },
        "types": { "terms": { "field": "type" } },
        
    },
    "post_filter": { "term": { "type": "repository" } }
}
                            </code></pre>
                </section>
            </section>

            <section data-title="Own experience with Elasticsearch">
                <section>
                    <h2>Own experience with Elasticsearch</h2>
                </section>

                <section>
                    <h2>How to use Ealsticsearch?</h2>
                    <p>Commonly used in addition to another database...</p>
                    <img height="350" data-src="images/overview.png" />
                </section>
            </section>

            <section>
                <h2>Questions?</h2>
            </section>

            <section>
                <h2>References</h2>
                <ul>
                    <li><a href="http://www.slideshare.net/jfaustin/introduction-to-elasticsearch-33976717"
                            target="_blank">Introduction
                            to Elasticsearch</a></li>
                    <li>
                        <a href="https://nullwords.wordpress.com/2013/04/18/inverted-indexes-inside-how-search-engines-work/"
                            target="_blank">Inverted Indexes – Inside How Search Engines Work</a></li>
                    <li><a href="http://operational.io/elk-stack-for-network-operations-reloaded/" target="_blank">ELK
                            Stack
                            for Network Operations</a></li>
                    <li><a href="http://www.slideshare.net/bigdatalondon/3-elastic-searchcostin-leau"
                            target="_blank">Search
                            and Analytics (using Elasticsearch)</a></li>
                    <li><a href="http://www.slideshare.net/sdenthumdas/introduction-to-elasticsearch-47385272"
                            target="_blank">Introduction to Elastic-search</a></li>
                </ul>
            </section>
        </div>

    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>

        // Full list of configuration options available at:
        // https://github.com/hakimel/reveal.js#configuration
        Reveal.initialize({
            controls: true,
            progress: true,
            history: true,
            center: true,

            transition: 'slide', // none/fade/slide/convex/concave/zoom

            // Optional reveal.js plugins
            dependencies: [
                {
                    src: 'lib/js/classList.js', condition: function () {
                        return !document.body.classList;
                    }
                },
                {
                    src: 'plugin/markdown/marked.js', condition: function () {
                        return !!document.querySelector('[data-markdown]');
                    }
                },
                {
                    src: 'plugin/markdown/markdown.js', condition: function () {
                        return !!document.querySelector('[data-markdown]');
                    }
                },
                {
                    src: 'plugin/highlight/highlight.js', async: true, callback: function () {
                        hljs.initHighlightingOnLoad();
                    }
                },
                { src: 'plugin/zoom-js/zoom.js', async: true },
                { src: 'plugin/notes/notes.js', async: true }
            ]
        });

    </script>

</body>

</html>